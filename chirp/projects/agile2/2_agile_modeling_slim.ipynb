{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AXQAcreKedWU"
   },
   "outputs": [],
   "source": [
    "#@title Imports. { vertical-output: true }\n",
    "from pathlib import Path\n",
    "from chirp.projects.agile2.agile_modeling_state import agile2_config, agile2_state, download_embeddings, Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "Here we set some configuration for names and local filepaths and initialize our agile modeling workflow.\n",
    "\n",
    "Your Ecosounds \"auth_token\" can be found by logging in to https://www.ecosounds.org, then clicking on your profile picture in the top left. You can copy your auth token from this profile page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = agile2_config(\n",
    "  #@markdown Location of database containing audio embeddings.\n",
    "  # db_path=\"/phil/perch_projects/ci/agile/hoplite_test/db/db.sqlite\", #@param {type:'string'}\n",
    "  db_path=\"\", #@param {type:'string'}\n",
    "  search_dataset_name=\"\", #@param {type:'string'}\n",
    "  #@markdown Identifier (eg, name) to attach to labels produced during validation.\n",
    "  annotator_id=\"\", #@param {type:'string'}\n",
    "  baw_config= {\n",
    "    'auth_token': \"\",  #@param {type:'string'}\n",
    "    'domain': 'api.ecosounds.org'\n",
    "  },\n",
    "  embeddings_folder=\"\", #@param {type:'string'}\n",
    ")\n",
    "\n",
    "config.from_json(\"../../../local/esa/agile_config.json\")\n",
    "\n",
    "agile = agile2_state(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linking to google drive\n",
    "\n",
    "We will need somewhere to read and write files. This colab environment where the notebook is running does not persist between sessions, so we will link to google drive for access to persistent storage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "except:\n",
    "    print(\"colab not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# If you followed the above instructions for creating a shortcut to the Drive folder, \n",
    "# you should be able to navigate to this directory in the left hand \"Files\" menu \n",
    "# in this Colab (indicated by the Folder icon on the far left menu).\n",
    "\n",
    "base_folder = '/content/drive/My Drive/'\n",
    "\n",
    "# This is the location on google drive that this tutorial will use to save data.\n",
    "working_folder = base_folder + 'esa2024_data/'\n",
    "\n",
    "if not config.db_path or config.db_path == \"\":\n",
    "  config.db_path = working_folder + 'hoplite_db/db.sqlite'\n",
    "\n",
    "if not config.embeddings_folder or config.embeddings_folder == \"\":\n",
    "  config.embeddings_folder = working_folder + 'embeddings/'\n",
    "\n",
    "if not config.labeled_examples_folder or config.labeled_examples_folder == \"\":\n",
    "  config.labeled_examples_folder = working_folder + 'labeled_examples/'\n",
    "\n",
    "\n",
    "Path(config.labeled_examples_folder).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download audio embeddings to the working folder\n",
    "# this might take a while\n",
    "\n",
    "download_embeddings('powerful_owl_subset', config.embeddings_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create embeddings database\n",
    "\n",
    "Here we retrieve the files of embeddings for the recordings that we will be searching in and put them in the right format for working with them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the downloaded embeddings, create a database of embeddings.\n",
    "# This database links labels to embeddings so we can train our classifier\n",
    "# this might take a while\n",
    "agile.create_database(config.embeddings_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agile.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVdLJJd9gnjo"
   },
   "source": [
    "# Search\n",
    "\n",
    "Here, we take a single example and find the examples in our search set which most closely match that example. This is a way to get started with a labelled training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ig3L5dsy3mr"
   },
   "outputs": [],
   "source": [
    "#@title Load query audio. { vertical-output: true }\n",
    "\n",
    "# Put your labelled examples in a folder on your mounted Google Drive, \n",
    "# then specify the path here. \n",
    "path_to_labeled_examples = config.labeled_examples_folder\n",
    "audio_files = Helpers.list_audio_files(path_to_labeled_examples)\n",
    "\n",
    "# choose one of the audio examples in the labeled examples folder\n",
    "query_uri = audio_files[0]\n",
    "\n",
    "# or specify a path or url\n",
    "#@markdown The `query_uri` can be a URL, filepath, or Xeno-Canto ID\n",
    "#@markdown (like `xc777802`, containing an Eastern Whipbird (`easwhi1`)).\n",
    "#query_uri = \"../../../local/esa/20230513T150000+0700_Site-109_1376880___755.0.wav\"  #@param {type:'string'}\n",
    "\n",
    "agile.embed_query(query_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHUJ_NwQWZNB"
   },
   "outputs": [],
   "source": [
    "#@markdown Our target call-type label\n",
    "query_label = 'powerful_owl'  #@param {type:'string'}\n",
    "#@markdown Number of results to retrieve.\n",
    "num_results = 40  #@param\n",
    "#@markdown Number of (randomly selected) database entries to search over.\n",
    "sample_size = 1_000_000  #@param\n",
    "#@markdown When margin sampling, target this logit.\n",
    "target_score = 1.0  #@param\n",
    "\n",
    "agile.search_with_query(query_label, num_results, sample_size, target_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3sIkOqlXzKB"
   },
   "outputs": [],
   "source": [
    "#@title Save data labels. { vertical-output: true }\n",
    "\n",
    "agile.save_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o65wpjvyYft-"
   },
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qtsJkgcPYg6z"
   },
   "outputs": [],
   "source": [
    "#@title Classifier training. { vertical-output: true }\n",
    "\n",
    "#@markdown Set of labels to classify. If None, auto-populated from the DB.\n",
    "target_labels = None  #@param\n",
    "learning_rate = 1e-3  #@param\n",
    "weak_neg_weight = 0.05  #@param\n",
    "l2_mu = 0.000  #@param\n",
    "num_steps = 128  #@param\n",
    "train_ratio = 0.01  #@param\n",
    "batch_size = 128  #@param\n",
    "weak_negatives_batch_size = 128  #@param\n",
    "loss_fn_name = 'bce'  #@param ['hinge', 'bce']\n",
    "agile.train_classifier(target_labels, learning_rate, weak_neg_weight, l2_mu, num_steps, train_ratio, batch_size, weak_negatives_batch_size, loss_fn_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3N6dzhetkG1"
   },
   "outputs": [],
   "source": [
    "#@title Review Classifier Results. { vertical-output: true }\n",
    "#@markdown Our target call-type label\n",
    "query_label = 'ciff'  #@param {type:'string'}\n",
    "#@markdown Number of results to retrieve.\n",
    "num_results = 40  #@param\n",
    "#@markdown Number of (randomly selected) database entries to search over.\n",
    "sample_size = 1_000_000  #@param\n",
    "#@markdown When margin sampling, target this logit.\n",
    "target_score = 3.0  #@param\n",
    "\n",
    "agile.search_with_classifier(query_label, num_results, sample_size, target_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kEk15jw_B8xL"
   },
   "outputs": [],
   "source": [
    "#@title Save data labels. { vertical-output: true }\n",
    "\n",
    "agile.save_labels()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "last_runtime": {
    "build_target": "",
    "kind": "local"
   },
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
